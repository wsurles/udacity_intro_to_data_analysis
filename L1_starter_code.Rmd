---
title: "L1_starter_code"
author: "William Surles"
date: "January 21, 2017"
output:
  html_document: default
  html_notebook: null
---

This is just me copying the python class work into R.  
Its helpful for me to think in different languages about what I am trying to do.

***

## Set up

```{r, echo=F}

options(width=100)

```

```{r, message=F}

library(readr)
library(dplyr)
library(ggvis)
library(DT)

```

***

## Load Data from CSVs

```{r, echo=T, eval=T, cache=T}

enrollments <- read.csv("data/enrollments.csv")
engagement <- read.csv("data/daily_engagement.csv")
project <- read.csv("data/project_submissions.csv")

str(enrollments)
str(engagement)
str(project)

```

Read more about the `readr` package [here](https://blog.rstudio.org/?s=readr)

Also note that the `str` function is really useful to get a glimpse of the data. 

***

## Fixing Data Types

```{r, echo=T, eval=T, cache=T}

## Enrollmenets
enrollments$join_date <- as.Date(enrollments$join_date)
enrollments$cancel_date <- as.Date(enrollments$cancel_date)
enrollments$is_canceled <- as.logical(enrollments$is_canceled)
enrollments$is_udacity <- as.logical(enrollments$is_udacity)

str(enrollments)

## Daily Engagment
engagement$utc_date <- as.Date(engagement$utc_date)
engagement$num_courses_visited <- as.integer(engagement$num_courses_visited)
engagement$lessons_completed <- as.integer(engagement$lessons_completed)
engagement$projects_completed <- as.integer(engagement$projects_completed)

str(engagement)

## Project Submissions
project$creation_date <- as.Date(project$creation_date)
project$completion_date <- as.Date(project$completion_date)

str(project)
```

***

## Investigating the data

```{r, echo=T, eval=T, cache=T}

str(enrollments)

n_distinct(enrollments$account_key)

str(engagement)

n_distinct(engagement$acct)

str(project)

n_distinct(project$account_key)

```

***

## Problems in the Data

```{r, echo=T, eval=T, cache=T}

engagement <- rename(engagement, account_key = acct)
str(engagement)
```

***

## Missing Engagement Records

```{r, echo=T, eval=T, cache=T}

u_account_enrollments <- unique(enrollments$account_key)
u_account_engagement <- unique(engagement$account_key)

length(u_account_enrollments)
length(u_account_engagement)

length(u_account_enrollments) - length(u_account_engagement)

setdiff(u_account_enrollments, u_account_engagement)
setdiff(u_account_engagement, u_account_enrollments)


```

So there are 65 more accounts in enrollment than engagement.

There are no accounts in engagement that are not in enrollment.

I guess some students enroll and then do nothing at all. 

```{r, echo=T, eval=T, cache=T}
anti_join(enrollments, engagement) %>%
  arrange(account_key) %>%
  head(10)

```

Yeah, looks like some students join and then cancel on the same date. 
I also see some students signing up multiple times.
Or even signing up and canceling multiple times on the same day. 

***

## Checking for more problem records

```{r, echo=T, eval=T, cache=T}

anti_join(enrollments, engagement) %>%
  arrange(account_key) %>% 
  filter(status == 'current' | days_to_cancel > 0) 

```

There is one student that is still current, but apparently has no engagement data.
That student may be a data error worth checking into, or maybe they just
have not used the platform at all since signing up

Another student has enrolled twice and cancelled way later but still had no engageent data. 

***

## Tracking down the remaining problems

```{r, echo=T, eval=T, cache=T}

table(enrollments$is_udacity)

enrollments %>% 
  filter(is_udacity == T)

dim(enrollments)
dim(engagement)
dim(project)

enrollments <- enrollments %>% 
  filter(is_udacity == F)

engagement <- engagement %>% 
  filter(account_key %in% enrollments$account_key)

project <- project %>% 
  filter(account_key %in% enrollments$account_key)

dim(enrollments)
dim(engagement)
dim(project)

```

There is no need to rename these data frames.  
I have the original data and can easily load that if I need to see it. 

My number for projects is lower than what I had in python. 
There must be some accounts in the project df that are not in the enrollments.
In python I compared to the list of udacity accounts. 
Here I removed all accounts not in the enrollments df. 

*** 

## Refining the question

Create a dictionary named paid_students containing all students who either
haven't canceled yet or who remained enrolled for more than 7 days. The keys
should be account keys, and the values should be the date the student enrolled.

Those are the pythong instructions. In R I'll keep the data in a dataframe. 

At this point I start to get curious and really want to see the data.  
Seeing the data in a chart can really help. 
In the python class I guess they are just taking it a step at a time.  
But my first step us usually to make tables and histograms of data. 
So, im gonna go ahead and do that. 

```{r, echo=T, eval=T, cache=T}

str(enrollments)

table(enrollments$days_to_cancel)

```


```{r, echo=T, eval=T, cache=F, width=100}

enrollments %>%
  ggvis(~days_to_cancel) %>%
  layer_histograms(width=1)

```

There are some spikes in the cancel dates.   
Maybe its on the month or something.  
I'll have to look into this later to see what that pattern is. 

```{r, echo=T, eval=T, cache=T}

enrollments %>%
  arrange(account_key, join_date) %>%
  head()

```

We will also want to only keep the max date for each account.  
Some students have multiple enrollments. 

```{r, echo=T, eval=T, cache=T}

paid_students <- enrollments %>%
  filter(
    is_canceled == F |
    days_to_cancel > 7
  ) %>% 
  group_by(account_key) %>%
  top_n(n=1, join_date) %>%
  data.frame()


paid_students %>%
  arrange(account_key, join_date) %>%
  head()

dim(paid_students)

```

I use the `top_n` function here with the df grouped by account_key to get 
the max date for each student.  
This and more techniques are in this [cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf).  
Some students had joined and canceled multiple times. 
For example, account_key 3 is now only in there once, with the most recent enrollment. 

***

## Getting Data from first week

```{r, echo=T, eval=T, cache=T, width=100}

head(engagement)
head(paid_students)

paid_engagement <- paid_students %>%
  right_join(engagement, by = "account_key") %>%
  mutate(date_diff = utc_date - join_date) %>%
  filter(date_diff < 7 & date_diff >=0) %>%
  select(account_key, join_date, utc_date, num_courses_visited, 
         total_minutes_visited, lessons_completed, projects_completed)

str(paid_engagement)
head(paid_engagement, 10)
```

I think its better to do a table join and then filter the data than to 
make a bunch of lists and dictionaries to compare.   
This is much less code and much more strait forward than the two functions
and two loops I had to make in python to get this to work. 
(albiet, we aren't using pandas yet so I hope there is a way to do something 
similar in python with dataframes)

***

## Exploring Student Engagement

All we want here is to see the total minutes spent in the first week per student.
And to look at some summary statistics of that data. 

```{r, echo=T, eval=T, cache=T}

paid_engagement2 <- paid_engagement %>%
  group_by(account_key) %>%
  summarize(
    count = n(),
    total_min = sum(total_minutes_visited),
    join_date = min(join_date),
    max_utc_date = max(utc_date),
    min_utc_date = min(utc_date)
    ) %>%
  arrange(desc(count))

head(paid_engagement2, 20)

table(paid_engagement2$count)

paid_engagement2 %>% arrange(desc(total_min)) %>% head()

summary(paid_engagement2)

```

**Comments on the Process**  
That was pretty easy. Group by and summarize is how its done in sql and its also
a very simple step to do in R.  

I am also adding other values so I can check on the data as a whole. 

The process in the python class, looping and putting values and lists into dictionaries 
and then looping to see the max values one at a time,
is not really the natural way I would think about this step.

We can easily see already that there are some counts that are off.  
The max should be 7. Lets quickly assess.

## Debugging data analysis code

Okay, its clear that this is a systemic problem. Its in all of the data.  
The `max_utc_date` looks good, but the `min_utc_date` is way before the join date.  
We need to go back to our last step and fix the function where we calc the `paid_engagement` data and 
add a filter to limit the `utc_date` to be greater than or equal to the `join_date`.   
There are students that enrolled multiple times and so we are picking up data
from their previous enrollments. 

Sweet, that fixed it. 

**Wondering about the data collection**  
Looking at the max for `total_min`...
3564 / 60 = `r 3564 / 60` hours. 

Thats a lot in one week. More than a full time job. That students wasn't trying to 
waste any time to learn some data analysis.   
I wonder how they calculate the minutes. Is it just time the webpage is open. 
Sometimes I have the page open while I am working in the jupyter notebook on my machine. 
But somethimes I have the page open while I watch football highlights from last weekend. 
That would not really be a fair count of minutes. 

***

## Lessons Completed in first week

Normally, I would just add this to the summary above.  
There is no reason that we can't summarize all the columns we care about by account_key
all in one step.   
But here, to keep in line with the python class sections I will just do it again. 

```{r, echo=T, eval=T, cache=T}

head(paid_engagement)

paid_engagement3 <- paid_engagement %>%
  group_by(account_key) %>%
  summarize(
    count = n(),
    total_min = sum(total_minutes_visited),
    total_lessons = sum(lessons_completed),
    total_projects = sum(projects_completed),
    join_date = min(join_date),
    max_utc_date = max(utc_date),
    min_utc_date = min(utc_date)
    ) %>%
  arrange(desc(total_lessons))

head(paid_engagement3, 10)

table(paid_engagement3$total_lessons)

summary(paid_engagement3)

```

***

## Number of visits in first week

Again, This would simple be a calculation added to the data crunching above.
Here we will first make a `has_visited` field with a mutate, 
and then sum it up like the rest. 
I'll do it all again here so we have the full crunched data set to view.

```{r, echo=T, eval=T, cache=T}

head(paid_engagement)

paid_engagement4 <- paid_engagement %>%
  mutate(has_visited = num_courses_visited > 0) %>%
  group_by(account_key) %>%
  summarize(
    count = n(),
    total_min = sum(total_minutes_visited),
    total_lessons = sum(lessons_completed),
    total_projects = sum(projects_completed),
    total_days_visited = sum(has_visited),
    join_date = min(join_date),
    max_utc_date = max(utc_date),
    min_utc_date = min(utc_date)
    ) %>%
  arrange(desc(total_days_visited))

head(paid_engagement4, 10)

table(paid_engagement4$total_days_visited)

summary(paid_engagement4)
```

***

## Splitting out Passing Students

First lets just explore this new data set a bit. 
```{r, echo=T, eval=T, cache=T}

head(project)
table(project$assigned_rating)
table(project$lesson_key)

```

We can see that there are several projects in this set. 

We can also see there are `PASSED` and `DISTINCTION` ratings which should be counted.

```{r, echo=T, eval=T, cache=T}

project %>%
  filter(
    lesson_key %in% c('746169184', '3176718735'),
    account_key == 133
    ) %>%
  arrange(completion_date) 

```

Also, we see that many students will have multiple ratings for this project. 
For example, student 133 did it 6 times before completing. 
I'm not sure if it took them 7 days to completed it while logging into udacity, or if they
they submitted it incomplete or what. But we will definitely need to break it down by account key
so we don't double count accounts. 

Aight, lets get this unique list of students that have passed. 

```{r, echo=T, eval=T, cache=T}

project_passing <- project %>%
  filter(
    lesson_key %in% c('746169184', '3176718735'),
    assigned_rating %in% c('PASSED','DISTINCTION')
    ) %>%
  group_by(account_key) %>%
  summarize(n = n()) %>%
  arrange(desc(n))

project_passing

```

This data frame has the unique list of students that have passes the projet
as well as the number of times they have passed. 

There are 647 students that have passed the project. 

Interestingly, some of these students passed the project multiple times. 

Maybe they went back through the class again to try and complete it and used there initial project code. 
One student passed the project 3 times. 

```{r, echo=T, eval=T, cache=T}

project %>%
  filter(
    lesson_key %in% c('746169184', '3176718735'),
    assigned_rating %in% c('PASSED','DISTINCTION'),
    account_key %in% c(508,118,310,316)
    ) %>%
  arrange(account_key, completion_date)

```


Note: There is no need to splid the passing and non passing engagment into
two separate data frames. I can easily filter the engagment data frame
by the list of accounts in the project passing or non passing data frmaes. 

***

## Comparing the Two Students Groups

Here we do exacly what we did above to summarize the engagement data but this time 
we will first filter by the list of passing and non-passing students. Thats it really.

Here I can do all the summaries at once. There is no reason to split it up. 

```{r, echo=T, eval=T, cache=T}

paid_engagement_passing <- paid_engagement %>%
  filter(account_key %in% project_passing$account_key) %>%
  mutate(has_visited = num_courses_visited > 0) %>%
  group_by(account_key) %>%
  summarize(
    count = n(),
    total_min = sum(total_minutes_visited),
    total_lessons = sum(lessons_completed),
    total_projects = sum(projects_completed),
    total_days_visited = sum(has_visited)
    ) %>%
  arrange(desc(total_min))

head(paid_engagement_passing, 10)

summary(paid_engagement_passing)

```

And the same for non passing students...

```{r, echo=T, eval=T, cache=T}

paid_engagement_non_passing <- paid_engagement %>%
  filter(!(account_key %in% project_passing$account_key))  %>%
  mutate(has_visited = num_courses_visited > 0) %>%
  group_by(account_key) %>%
  summarize(
    count = n(),
    total_min = sum(total_minutes_visited),
    total_lessons = sum(lessons_completed),
    total_projects = sum(projects_completed),
    total_days_visited = sum(has_visited)
    ) %>%
  arrange(desc(total_min))

head(paid_engagement_non_passing, 10)

summary(paid_engagement_non_passing)

```

***

## Making Histograms

```{r, echo=T, eval=T, cache=T}

## total minutes
paid_engagement_passing %>% ggvis(~total_min) %>% layer_histograms()
paid_engagement_non_passing %>% ggvis(~total_min) %>% layer_histograms()

## total lessons
paid_engagement_passing %>% ggvis(~total_lessons) %>% layer_histograms()
paid_engagement_non_passing %>% ggvis(~total_lessons) %>% layer_histograms()

## total days visited
paid_engagement_passing %>% ggvis(~total_days_visited) %>% layer_histograms()
paid_engagement_non_passing %>% ggvis(~total_days_visited) %>% layer_histograms()

```

***

## Improving Plots and Sharing Findings 

These already look pretty good here with ggvis. There is no need to download
a library to make another library look nicer (matplotlib -> seaborn). That seems weird. 
Annwyas. I'm done with the first lesson. Woot! 