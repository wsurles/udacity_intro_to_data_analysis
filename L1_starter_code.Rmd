---
title: "L1_starter_code"
author: "William Surles"
date: "January 21, 2017"
output: 
  html_document:
    self_contained: yes
    theme: flatly
    highlight: tango
---

This is just me copying the python class work into R.  
Its helpful for me to think in different languages about what I am trying to do.

***

## Set up

```{r, echo=F}

options(width=100)

```

```{r, message=F}

library(readr)
library(dplyr)
library(ggvis)
library(DT)

```

***

## Load Data from CSVs

```{r, echo=T, eval=T, cache=T}

enrollments <- read.csv("data/enrollments.csv")
engagement <- read.csv("data/daily_engagement.csv")
project <- read.csv("data/project_submissions.csv")

str(enrollments)
str(engagement)
str(project)

```

Read more about the `readr` package [here](https://blog.rstudio.org/?s=readr)

Also note that the `str` function is really useful to get a glimpse of the data. 

***

## Fixing Data Types

```{r, echo=T, eval=T, cache=T}

## Enrollmenets
enrollments$join_date <- as.Date(enrollments$join_date)
enrollments$cancel_date <- as.Date(enrollments$cancel_date)
enrollments$is_canceled <- as.logical(enrollments$is_canceled)
enrollments$is_udacity <- as.logical(enrollments$is_udacity)

str(enrollments)

## Daily Engagment
engagement$utc_date <- as.Date(engagement$utc_date)
engagement$num_courses_visited <- as.integer(engagement$num_courses_visited)
engagement$lessons_completed <- as.integer(engagement$lessons_completed)
engagement$projects_completed <- as.integer(engagement$projects_completed)

str(engagement)

## Project Submissions
project$creation_date <- as.Date(project$creation_date)
project$completion_date <- as.Date(project$completion_date)

str(project)
```

***

## Investigating the data

```{r, echo=T, eval=T, cache=T}

str(enrollments)

n_distinct(enrollments$account_key)

str(engagement)

n_distinct(engagement$acct)

str(project)

n_distinct(project$account_key)

```

***

## Problems in the Data

```{r, echo=T, eval=T, cache=T}

engagement <- rename(engagement, account_key = acct)
str(engagement)
```

***

## Missing Engagement Records

```{r, echo=T, eval=T, cache=T}

u_account_enrollments <- unique(enrollments$account_key)
u_account_engagement <- unique(engagement$account_key)

length(u_account_enrollments)
length(u_account_engagement)

length(u_account_enrollments) - length(u_account_engagement)

setdiff(u_account_enrollments, u_account_engagement)
setdiff(u_account_engagement, u_account_enrollments)


```

So there are 65 more accounts in enrollment than engagement.

There are no accounts in engagement that are not in enrollment.

I guess some students enroll and then do nothing at all. 

```{r, echo=T, eval=T, cache=T}
anti_join(enrollments, engagement) %>%
  arrange(account_key) %>%
  head(10)

```

Yeah, looks like some students join and then cancel on the same date. 
I also see some students signing up multiple times.
Or even signing up and canceling multiple times on the same day. 

***

## Checking for more problem records

```{r, echo=T, eval=T, cache=T}

anti_join(enrollments, engagement) %>%
  arrange(account_key) %>% 
  filter(status == 'current' | days_to_cancel > 0) 

```

There is one student that is still current, but apparently has no engagement data.
That student may be a data error worth checking into, or maybe they just
have not used the platform at all since signing up

Another student has enrolled twice and cancelled way later but still had no engageent data. 

***

## Tracking down the remaining problems

```{r, echo=T, eval=T, cache=T}

table(enrollments$is_udacity)

enrollments %>% 
  filter(is_udacity == T)

dim(enrollments)
dim(engagement)
dim(project)

enrollments <- enrollments %>% 
  filter(is_udacity == F)

engagement <- engagement %>% 
  filter(account_key %in% enrollments$account_key)

project <- project %>% 
  filter(account_key %in% enrollments$account_key)

dim(enrollments)
dim(engagement)
dim(project)

```

There is no need to rename these data frames.  
I have the original data and can easily load that if I need to see it. 

My number for projects is lower than what I had in python. 
There must be some accounts in the project df that are not in the enrollments.
In python I compared to the list of udacity accounts. 
Here I removed all accounts not in the enrollments df. 

*** 

## Refining the question

Create a dictionary named paid_students containing all students who either
haven't canceled yet or who remained enrolled for more than 7 days. The keys
should be account keys, and the values should be the date the student enrolled.

Those are the pythong instructions. In R I'll keep the data in a dataframe. 

At this point I start to get curious and really want to see the data.  
Seeing the data in a chart can really help. 
In the python class I guess they are just taking it a step at a time.  
But my first step us usually to make tables and histograms of data. 
So, im gonna go ahead and do that. 

```{r, echo=T, eval=T, cache=T}

str(enrollments)

table(enrollments$days_to_cancel)

```


```{r, echo=T, eval=T, cache=F, width=100}

enrollments %>%
  ggvis(~days_to_cancel) %>%
  layer_histograms(width=1)

```

There are some spikes in the cancel dates.   
Maybe its on the month or something.  
I'll have to look into this later to see what that pattern is. 

```{r, echo=T, eval=T, cache=T}

enrollments %>%
  arrange(account_key, join_date) %>%
  head()

```

We will also want to only keep the max date for each account.  
Some students have multiple enrollments. 

```{r, echo=T, eval=T, cache=T}

paid_students <- enrollments %>%
  filter(
    is_canceled == F |
    days_to_cancel > 7
  ) %>% 
  group_by(account_key) %>%
  top_n(n=1, join_date) %>%
  data.frame()


paid_students %>%
  arrange(account_key, join_date) %>%
  head()

dim(paid_students)

```

I use the `top_n` function here with the df grouped by account_key to get 
the max date for each student.  
This and more techniques are in this [cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf).  
Some students had joined and canceled multiple times. 
For example, account_key 3 is now only in there once, with the most recent enrollment. 

***

## Getting Data from first week

```{r, echo=T, eval=T, cache=T, width=100}

head(engagement)
head(paid_students)

paid_engagement <- paid_students %>%
  right_join(engagement, by = "account_key") %>%
  mutate(date_diff = utc_date - join_date) %>%
  filter(date_diff < 7 & date_diff >=0) %>%
  select(account_key, join_date, utc_date, num_courses_visited, 
         total_minutes_visited, lessons_completed, projects_completed)

str(paid_engagement)
head(paid_engagement, 10)
```

I think its better to do a table join and then filter the data than to 
make a bunch of lists and dictionaries to compare.   
This is much less code and much more strait forward than the two functions
and two loops I had to make in python to get this to work. 
(albiet, we aren't using pandas yet so I hope there is a way to do something 
similar in python with dataframes)

***

## Exploring Student Engagement

All we want here is to see the total minutes spent in the first week per student.
And to look at some summary statistics of that data. 

```{r, echo=T, eval=T, cache=T}

paid_engagement2 <- paid_engagement %>%
  group_by(account_key) %>%
  summarize(
    count = n(),
    total_min = sum(total_minutes_visited),
    join_date = min(join_date),
    max_utc_date = max(utc_date),
    min_utc_date = min(utc_date)
    ) %>%
  arrange(desc(count))

head(paid_engagement2, 20)

table(paid_engagement2$count)

paid_engagement2 %>% arrange(desc(total_min)) %>% head()

summary(paid_engagement2)

```

**Comments on the Process**  
That was pretty easy. Group by and summarize is how its done in sql and its also
a very simple step to do in R.  

I am also adding other values so I can check on the data as a whole. 

The process in the python class, looping and putting values and lists into dictionaries 
and then looping to see the max values one at a time,
is not really the natural way I would think about this step.

**Debugging**    
We can easily see already that there are some counts that are off.  
The max should be 7. Lets quickly assess.

Okay, its clear that this is a systemic problem. Its in all of the data.  
The `max_utc_date` looks good, but the `min_utc_date` is way before the join date.  
We need to go back to our last step and fix the function where we calc the `paid_engagement` data and 
add a filter to limit the `utc_date` to be greater than or equal to the `join_date`.   
There are students that enrolled multiple times and so we are picking up data
from their previous enrollments. 

Sweet, that fixed it. 

**Wondering about the data collection**  
Looking at the max for `total_min`...
3564 / 60 = `r 3564 / 60` hours. 

Thats a lot in one week. More than a full time job. That students wasn't trying to 
waste any time to learn some data analysis.   
I wonder how they calculate the minutes. Is it just time the webpage is open. 
Sometimes I have the page open while I am working in the jupyter notebook on my machine. 
But somethimes I have the page open while I watch football highlights from last weekend. 
That would not really be a fair count of minutes. 

***

## Debugging data analysis code

```{r, echo=T, eval=T, cache=T}

```

***

## Lessons Completed in first week

```{r, echo=T, eval=T, cache=T}

```

***

## Number of visits in first week

```{r, echo=T, eval=T, cache=T}

```

***

## Splitting out Passing Students

```{r, echo=T, eval=T, cache=T}

```

***

## Comparing the Two Students Groups

```{r, echo=T, eval=T, cache=T}

```

***

## Making Histograms

```{r, echo=T, eval=T, cache=T}

```

***

## Improving Plots and Sharing Findings 

```{r, echo=T, eval=T, cache=T}

```
